{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":12500,"databundleVersionId":1375107,"sourceType":"competition"}],"dockerImageVersionId":31192,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Import library","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nimport warnings\n\nimport re\n# import unidecode\n\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom scipy import sparse\nfrom sklearn.decomposition import TruncatedSVD\n\nimport lightgbm as lgb\nfrom sklearn.metrics import roc_auc_score\n\nwarnings.filterwarnings(action=\"ignore\")\n\nDATA_PATH = \"/kaggle/input/jigsaw-unintended-bias-in-toxicity-classification/\"","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_train = pd.read_csv(DATA_PATH+\"train.csv\")\ndf_test = pd.read_csv(DATA_PATH+\"test.csv\")\ndf_sample = pd.read_csv(DATA_PATH+\"sample_submission.csv\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Preprocessing","metadata":{}},{"cell_type":"code","source":"# !pip install Unidecode","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 나는 구경도 못했는데 url이 있었다네 아니 뭔\n'''\nurl_pattern = r\"https?://\\S+|www.\\.\\S+\"\n'''","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 그리고 unicode 변환은 또 뭐야\n'''\n\n'''","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 첫번째 질문\n# 그것보다는 불용어?처리를 하는게 좋지 않을까 싶었다. 추가적으로 하자면 .lower()처리정도?\n# 그런데 BERT같은 transformer계열 모델을 사용한다면 attention으로 문장 내 단어간 관계을 알 수 있다.\n# 그럼 제거 안해도 되나?\n\n# 두번째 질문\n# 간단한 방식, TF-IDF나 Word2Vec 같은걸 이용하는 방식도 해보고 싶다.\n# 나는 이것들이 뭔지도 잘 모르니까\n# 우리의 baseline은 그런 의미에서 간단하다.","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def simple_clean_text(text):\n    text = str(text)\n    text.lower() # 같은 단어의 대,소문자 버전을 동일하게 인식하기 위해\n    text = \" \".join(text.split()) # 공백을 한칸으로만 깔끔하게 정리\n    # TF-IDF나 Word2Vec 같은 임베딩은 공백(\" \")을 기준으로 단어를 쪼갬(tokenize)\n    # 공백이 2칸 이상이면 빈 문자열 생김\n    return text\n\ndf_train['clean_text'] = df_train['comment_text'].apply(simple_clean_text)\ndf_test['clean_text'] = df_test['comment_text'].apply(simple_clean_text)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pd.set_option(\"display.max_colwidth\", None)\ndf_train.loc[34:43][['comment_text']]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_train.loc[34:43][['clean_text']]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%time # 해당 셀 실행후 소요 시간을 출력해줌\n\n# Encoding : 빠른 실행과 수준확인을 위해서 TF-IDF를 사용\ntfidf = TfidfVectorizer(\n    max_features = 100000, # 전체 단어 중 상위 10만개 사용 (10만 차원)\n    ngram_range = (1,2), # unigram(단일단어) + bigram(연속단어)\n    min_df = 3, # 너무 적게 등장하는 단어는 제외\n    max_df = 0.9, # 너무 자주 등장하는 단어도 제외\n    sublinear_tf = True # 단어 빈도에 로그 적용해 과도한 빈도 영향 완화\n    # 일반 TF: 단순 count(1->10->100) / 로그 TF: (1->1+log10->1+log100)\n    # 100번 등장한 단어가 1번 등장한 단어보다 100배 더 중요하다는 건 과장일 수 있음\n)\n\nX_train = tfidf.fit_transform(df_train['clean_text'])\nX_test = tfidf.transform(df_test['clean_text'])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X_train[34:43].toarray()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 중간 저장\n# save_npz는 sparse 구조 그대로 저장. TF-IDF결과는 sparse임\nsparse.save_npz(\"X_train_tfidf.npz\", X_train)\nsparse.save_npz(\"X_test_tfidf.npz\", X_test)\n\n# 로드\n# X_train = sparse.load_npz(\"X_train_tfidf.npz\")\n# X_test  = sparse.load_npz(\"X_test_tfidf.npz\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%time # 해당 셀 실행후 소요 시간을 출력해줌\n\n# 차원이 10만개는 좀 많을 수도 있으니 차원축소\n# 10만개는 PCA처리 -> covariance matrix 연산값이 너무 커짐\n# sparse matrix 형태이므로 SVD 사용\n\nsvd = TruncatedSVD(n_components=5000, random_state=42)\nX_train_svd = svd.fit_transform(X_train)\nX_test_svd = svd.transform(X_test)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 중간 저장\n# savez_compressed는 dense array로 변환해서 저장, SVD결과는 dense임\nnp.savez_compressed(\n    'svd_features.npz',\n    X_train_svd=X_train_svd,\n    X_test_svd=X_test_svd\n)\n\n# 로드\n# data = np.load('svd_features.npz')\n# X_train_svd = data['X_train_svd']\n# X_test_svd = data['X_test_svd']","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Baseline: LightGBM","metadata":{}},{"cell_type":"code","source":"%%time # 해당 셀 실행후 소요 시간을 출력해줌\n\ny = df_train['target'].values\n\nparams = {\n    'objective':'regression',\n    'metric':'rmse', # 학습용 손실함수\n    'boosting_type':'gbdt', # 학습방식 = {gbdt,dart,goss}\n    'learning_rate':0.05,\n    'n_estimators':1000,\n    'subsample':0.8,\n    'n_jobs':-1,\n    'colsample_bytree': 0.8,\n    'num_leaves': 127,\n    'min_child_samples': 30,\n    'reg_alpha':0.1,\n    'reg_lambda':0.1,\n}\n\nlgbm = lgb.LGBMRegressor(**params)\nlgbm.fit(X_train_svd, y)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"y_pred = lgbm.predict(X_test_svd)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(y_pred)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"submission = pd.DataFrame({\n    'id': df_test['id'],\n    'prediction': y_pred\n})\n\nsubmission.to_csv('submission.csv', index=False)","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}